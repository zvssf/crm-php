#!/usr/bin/env python3
import os
import sys
import json
import re
from pathlib import Path

import pdfplumber


class VisaAppointmentParser:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –∑–∞–ø–∏—Å–∏ –≤ –≤–∏–∑–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - VFS Global (France, Poland, Bulgaria, UK/Seasonal worker –∏ —Ç.–ø.)
    - BLS Spain (–æ—Ç–¥–µ–ª—å–Ω–∞—è –≤–µ—Ç–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã)
    """

    def __init__(self, pdf_path: str):
        self.pdf_path = Path(pdf_path)
        if not self.pdf_path.exists():
            raise FileNotFoundError(f"PDF not found: {self.pdf_path}")

        self.full_text = ""
        self.provider = None

        self.meta = {
            "provider": None,
            "group_urn": None,
            "appointment_date": None,
            "appointment_time": None,
            "visa_category_global": None,
            "raw_text_locale": None,
        }

    # ---------------------- PUBLIC API ---------------------- #

    def parse(self) -> dict:
        # 1) —Å–Ω–∞—á–∞–ª–∞ —Ç—è–Ω–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (–¥–ª—è —à–∞–ø–∫–∏, –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ BLS)
        self._extract_text_with_layout()

        # 2) –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ –ø–æ–ª–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É
        self._detect_provider()

        # 3) –ø–∞—Ä—Å–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¥–∞—Ç–∞/–≤—Ä–µ–º—è/–∫–∞—Ç–µ–≥–æ—Ä–∏—è/–≥—Ä—É–ø–ø–∞)
        self._parse_global_metadata()

        # 4) –ø–∞—Ä—Å–∏–º –∑–∞—è–≤–∏—Ç–µ–ª–µ–π (VFS –∏–ª–∏ BLS)
        applicants = self._parse_applicants_from_pdf()
        applicants = self._filter_invalid_applicants(applicants)
        self._refine_visa_category_with_applicants(applicants)

        # –§–æ–ª–ª–±–µ–∫: –¥–∞—Ç–∞/–≤—Ä–µ–º—è –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∞–ø–ø–ª–∏–∫–∞–Ω—Ç–∞, –µ—Å–ª–∏ –≤ —à–∞–ø–∫–µ –ø—É—Å—Ç–æ
        if applicants:
            first = applicants[0]
            if not self.meta.get("appointment_date") and first.get("appointment_date"):
                self.meta["appointment_date"] = first["appointment_date"]
            if not self.meta.get("appointment_time") and first.get("appointment_time"):
                self.meta["appointment_time"] = first["appointment_time"]

        # –§–æ–ª–ª–±–µ–∫: group_urn –∏–∑ reference_number, –µ—Å–ª–∏ –≤ —à–∞–ø–∫–µ –æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω
        if not self.meta.get("group_urn") and applicants:
            base_candidates = set()

            for a in applicants:
                ref = (a.get("reference_number") or "").strip()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –≤—Ä–æ–¥–µ BUL67427091816/1, PLTR79622146950/3 –∏ —Ç.–ø.
                m = re.match(r"^([A-Z0-9]+)/\d+$", ref, flags=re.IGNORECASE)
                if m:
                    base_candidates.add(m.group(1))

            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω "–±–∞–∑–æ–≤—ã–π" –Ω–æ–º–µ—Ä ‚Äî —Å—á–∏—Ç–∞–µ–º –µ–≥–æ group_urn
            if len(base_candidates) == 1:
                base = base_candidates.pop()
                self.meta["group_urn"] = base

                # –ò –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —á–∏—Å—Ç–∏–º reference_number —É —Å–æ–≤–ø–∞–≤—à–∏—Ö –∑–∞—è–≤–∏—Ç–µ–ª–µ–π:
                # "BUL67427091816/1" -> "BUL67427091816"
                for a in applicants:
                    ref = (a.get("reference_number") or "").strip()
                    if re.match(rf"^{re.escape(base)}/\d+$", ref, flags=re.IGNORECASE):
                        a["reference_number"] = base

        result = {
            "source_file": os.path.basename(self.pdf_path),
            "provider": self.provider,
            "group_urn": self.meta.get("group_urn"),
            "appointment_date": self.meta.get("appointment_date"),
            "appointment_time": self.meta.get("appointment_time"),
            "visa_category_global": self.meta.get("visa_category_global"),
            "raw_text_locale": self.meta.get("raw_text_locale"),
            "applicants": applicants,
        }
        return result

    # ---------------------- BASIC TEXT ---------------------- #

    def _extract_text_with_layout(self):
        """
        –ó–∞–ø–æ–ª–Ω—è–µ–º self.full_text –∏ raw_text_locale.
        –≠—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –Ω–∞—à–∏—Ö –∑–∞–¥–∞—á (—Ç–∞–±–ª–∏—á–Ω—ã–π layout –±–µ—Ä—ë–º —á–µ—Ä–µ–∑ pdfplumber –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö).
        """
        self.full_text = self._extract_full_text() or ""

        txt = self.full_text
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ ‚Äî ru, –∏–Ω–∞—á–µ en
        if re.search(r"[–ê-–Ø–∞-—è–Å—ë]", txt):
            locale = "ru"
        else:
            locale = "en"
        self.meta["raw_text_locale"] = locale

    def _detect_provider(self):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ –ø–æ–ª–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É.
        """
        text = self.full_text or self._extract_full_text()

        if "BLS Spain Application Centre" in text:
            provider = "BLS Spain"
        elif "VFS Global" in text or "VFS G\nLOBAL" in text or "VFS G LOBAL" in text:
            provider = "VFS Global"
        elif "iDATA" in text:
            provider = "iDATA"
        else:
            provider = None

        self.meta["provider"] = provider
        self.provider = provider

    def _extract_full_text(self) -> str:
        parts = []
        with pdfplumber.open(self.pdf_path) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                parts.append(text)
        return "\n".join(parts)

    # ---------------------- GLOBAL META ---------------------- #

    def _normalize_time(self, text: str | None) -> str | None:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏:
        - –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞, –Ω–∞–ø—Ä. '09:30-10:00' ‚Üí –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ '09:30'
        - –æ—Å—Ç–∞–ª—å–Ω–æ–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å (–≤–∫–ª—é—á–∞—è '08:00 am', '8:45' –∏ —Ç.–ø.)
        """
        if not text:
            return None

        t = text.strip()

        # –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å –≤–æ–∑–º–æ–∂–Ω—ã–º am/pm —Å–ª–µ–≤–∞/—Å–ø—Ä–∞–≤–∞
        interval = re.match(
            r"^(\d{1,2}:\d{2}(?:\s*(?:am|pm|AM|PM))?)\s*[-‚Äì]\s*\d{1,2}:\d{2}(?:\s*(?:am|pm|AM|PM))?$",
            t,
        )
        if interval:
            return interval.group(1).strip()

        return t

    def _parse_global_metadata(self):
        """
        –ü–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ä–∞–∑–±–æ—Ä —à–∞–ø–∫–∏: provider, group_urn, date/time, visa category.
        """
        text = self.full_text
        lines_raw = text.splitlines()
        lines = [ln.strip() for ln in lines_raw]

        # --- Provider --- (–µ—Å–ª–∏ –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω)
        if not self.meta.get("provider"):
            if "BLS Spain Application Centre" in text:
                self.meta["provider"] = "BLS Spain"
            elif "VFS Global" in text or "VFS G\nLOBAL" in text or "VFS G LOBAL" in text:
                self.meta["provider"] = "VFS Global"
            elif "iDATA" in text:
                self.meta["provider"] = "iDATA"
            else:
                self.meta["provider"] = None

        # —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å self.provider
        self.provider = self.meta["provider"]

        # --- Visa Type (BLS Spain, –Ω–æ –º–æ–∂–µ—Ç –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å—Å—è –µ—â—ë –≥–¥–µ-—Ç–æ) ---
        m = re.search(r"Visa\s+Type[ \t]*:[ \t]*([^\n\r]+)", text)
        if m:
            self.meta["visa_category_global"] = m.group(1).strip()

        date_pattern = re.compile(
            r"(\d{2}[./-]\d{2}[./-]\d{4}|\d{4}[./-]\d{2}[./-]\d{2})"
        )
        time_pattern = re.compile(
            r"(\d{1,2}:\d{2}"
            r"(?:\s*(?:am|pm|AM|PM))?"
            r"(?:\s*-\s*\d{1,2}:\d{2}(?:\s*(?:am|pm|AM|PM))?)?)"
        )

        def next_non_empty_value(start_idx, max_steps=5, regex=None):
            for j in range(start_idx + 1, min(len(lines), start_idx + 1 + max_steps)):
                candidate = lines[j].strip()
                if not candidate:
                    continue
                if regex is None:
                    return candidate
                m_ = regex.search(candidate)
                if m_:
                    return m_.group(1)
            return None

        # --- Group URN (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ, –æ—Å–æ–±–µ–Ω–Ω–æ —É BLS) ---
        for i, ln in enumerate(lines):
            low = ln.lower()
            if "group urn" in low and self.meta["group_urn"] is None:
                m = re.search(r"Group\s+URN\s*[-:]\s*([A-Z0-9]+)", ln)
                if m:
                    self.meta["group_urn"] = m.group(1)
                else:
                    # –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –Ω–∏–∂–µ
                    val = next_non_empty_value(i, max_steps=3)
                    if val:
                        token = val.split()[0]
                        token = re.sub(r"[^A-Z0-9]", "", token)
                        if token:
                            self.meta["group_urn"] = token
                break

        # fallback: –∏—â–µ–º "–ø–æ—Ö–æ–∂—É—é" —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ group_urn –≤—Å—ë –µ—â—ë —Å—Ç—Ä–∞–Ω–Ω—ã–π
        if not self.meta["group_urn"] or len(self.meta["group_urn"]) < 5:
            for ln in lines:
                cand = ln.strip().replace(" ", "")
                if re.fullmatch(r"[A-Z]{2,4}\d{6,}", cand):
                    self.meta["group_urn"] = cand
                    break

        # --- Appointment Date / Time / Category (–ø–æ—Å—Ç—Ä–æ—á–Ω–æ) ---
        for i, ln in enumerate(lines):
            low = ln.lower()

            # Appointment Date
            if "appointment date" in low and self.meta["appointment_date"] is None:
                m = date_pattern.search(ln)
                if m:
                    self.meta["appointment_date"] = m.group(1)
                else:
                    v = next_non_empty_value(i, regex=date_pattern)
                    if v:
                        self.meta["appointment_date"] = v

            # Appointment Time
            if "appointment time" in low and self.meta["appointment_time"] is None:
                m = time_pattern.search(ln)
                if m:
                    self.meta["appointment_time"] = m.group(1)
                else:
                    v = next_non_empty_value(i, regex=time_pattern)
                    if v:
                        self.meta["appointment_time"] = v

            # Visa Category (VFS)
            if "visa category" in low and self.meta["visa_category_global"] is None:
                collected = []
                for j in range(i + 1, min(len(lines), i + 1 + 5)):
                    v = lines[j].strip()
                    if not v:
                        continue
                    vlow = v.lower()
                    if (
                        vlow.startswith("address")
                        or vlow.startswith("visa application center")
                        or vlow.startswith("visa application centre")
                        or vlow.startswith("number of")
                        or vlow.startswith("email id")
                    ):
                        break
                    collected.append(v)
                if collected:
                    self.meta["visa_category_global"] = " ".join(collected)

            # Category (–±–µ–∑ —Å–ª–æ–≤–∞ Visa)
            if (
                self.meta["visa_category_global"] is None
                and low.startswith("category")
            ):
                after = ln.split("Category", 1)[1].strip(" :\t-")
                parts = []
                if after:
                    parts.append(after)
                for j in range(i + 1, min(len(lines), i + 1 + 3)):
                    v = lines[j].strip()
                    if not v:
                        continue
                    vlow = v.lower()
                    if (
                        vlow.startswith("address")
                        or vlow.startswith("visa application center")
                        or vlow.startswith("visa application centre")
                        or vlow.startswith("number of")
                        or vlow.startswith("email id")
                    ):
                        break
                    parts.append(v)
                if parts:
                    self.meta["visa_category_global"] = " ".join(parts)

        # üîπ –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ä–µ–º—è –≤ —à–∞–ø–∫–µ (—Å—Ä–µ–∂–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã —Ç–∏–ø–∞ 09:30-10:00)
        if self.meta.get("appointment_time"):
            self.meta["appointment_time"] = self._normalize_time(
                self.meta["appointment_time"]
            )

    # ---------------------- APPLICANT PARSING ---------------------- #

    def _parse_applicants_from_pdf(self):
        # BLS Spain ‚Äî —Å–≤–æ–π –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä, –±–µ–∑ —Ç–∞–±–ª–∏—Ü —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
        if self.meta["provider"] == "BLS Spain":
            return self._parse_bls_spain()

        applicants = []
        with pdfplumber.open(self.pdf_path) as pdf:
            for page_index, page in enumerate(pdf.pages):
                page_applicants = self._parse_applicants_from_page(page)
                if page_applicants:
                    applicants.extend(page_applicants)
        return applicants

    # ---------- BLS Spain —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä ---------- #

    def _parse_bls_spain(self):
        """
        –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä BLS Spain.

        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ø—Ä–∏–º–µ—Ä —Å 1 –∑–∞—è–≤–∏—Ç–µ–ª–µ–º):

            Appointment Details
            Passport Appointment
            Applicant Name Reference Number Value Added Services
            Number Date & Time
            2025-10-01
            GUR***** AKG***** *****051 Premium
            13:30-13:45
            IST486202125425

        –ò–ª–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∑–∞—è–≤–∏—Ç–µ–ª—è–º–∏ ‚Äì —Ç–∞–∫–∏–µ –∂–µ –±–ª–æ–∫–∏ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è.
        """
        lines = self.full_text.splitlines()

        # –ò—â–µ–º –±–ª–æ–∫ "Appointment Details"
        start_idx = None
        for i, line in enumerate(lines):
            if line.strip().lower() == "appointment details":
                start_idx = i
                break

        if start_idx is None:
            return []

        # –†–µ–≥—ç–∫—Å–ø—ã –¥–ª—è –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏/—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
        date_re = re.compile(r"\d{4}-\d{2}-\d{2}")
        time_re = re.compile(r"\d{1,2}:\d{2}(?:-\d{1,2}:\d{2})?")
        ref_re = re.compile(r"[A-Z]{3}\d{9,}(?:/\d+)?")

        applicants = []

        i = start_idx + 1
        # –ü—Ä–æ–ª–∏—Å—Ç—ã–≤–∞–µ–º —à–∞–ø–∫—É —Ç–∞–±–ª–∏—Ü—ã –¥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞—Ç–æ–π
        while i < len(lines) and not date_re.fullmatch(lines[i].strip()):
            i += 1

        # –î–∞–ª—å—à–µ –æ–∂–∏–¥–∞–µ–º –±–ª–æ–∫–∏ –ø–æ 4 —Å—Ç—Ä–æ–∫–∏:
        #   –¥–∞—Ç–∞
        #   —Å—Ç—Ä–æ–∫–∞ "–§–ò–û + –ø–∞—Å–ø–æ—Ä—Ç (+ VAS)"
        #   –≤—Ä–µ–º—è
        #   reference number
        while i + 3 < len(lines):
            date_line = lines[i].strip()
            if not date_re.fullmatch(date_line):
                break

            name_pass = lines[i + 1].strip()
            time_line = lines[i + 2].strip()
            ref_line = lines[i + 3].strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –∏ reference
            if not time_re.fullmatch(time_line) or not ref_re.fullmatch(ref_line):
                break

            tokens = name_pass.split()
            if not tokens:
                break

            # --- –∏—â–µ–º –ø–∞—Å–ø–æ—Ä—Ç —Å –∫–æ–Ω—Ü–∞, —á—Ç–æ–±—ã –Ω–µ –ø–æ–π–º–∞—Ç—å VAS (Premium/Normal) ---
            passport = None
            name_tokens = tokens
            for idx_tok in range(len(tokens) - 1, -1, -1):
                tok = tokens[idx_tok]
                if self._passport_looks_valid(tok):
                    passport = tok
                    name_tokens = tokens[:idx_tok]
                    break

            # fallback: –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω —Å—á–∏—Ç–∞–µ–º –ø–∞—Å–ø–æ—Ä—Ç–æ–º
            if passport is None:
                passport = tokens[-1]
                name_tokens = tokens[:-1]

            name = " ".join(name_tokens) or None
            passport_masked = any(ch in passport for ch in "*xX")

            appointment_date = date_line

            # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ä–µ–º—è: '13:30-13:45' ‚Üí '13:30'
            time_norm = self._normalize_time(time_line)
            appointment_time = time_norm
            datetime_raw = (
                f"{appointment_date} {time_norm}".strip() if time_norm else appointment_date
            )

            # –≥–ª–æ–±–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —É–∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–∞ –≤ _parse_global_metadata
            global_cat = self.meta.get("visa_category_global")
            visa_category = (
                self._clean_visa_category_text(global_cat) if global_cat else None
            )

            applicants.append(
                {
                    "name": name,
                    "passport": passport,
                    "passport_masked": passport_masked,
                    "appointment_date": appointment_date,
                    "appointment_time": appointment_time,
                    "datetime_raw": datetime_raw,
                    "visa_category": visa_category,
                    "reference_number": ref_line,
                    "special_reference_number": None,
                }
            )

            i += 4

        return applicants

    # ---------- VFS / Generic —Ç–∞–±–ª–∏—Ü–∞ ---------- #

    def _parse_applicants_from_page(self, page):
        words = page.extract_words(
            keep_blank_chars=False,
            x_tolerance=2,
            y_tolerance=3,
        )
        if not words:
            return []

        lines = self._group_words_into_lines(words)
        if not lines:
            return []

        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —à–∞–ø–∫–∏: —Ç–∞–º –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏ "Applicant", –∏ "Passport"
        header_index = None
        for idx, line in enumerate(lines):
            text = " ".join(w["text"] for w in line).lower()
            if "applicant" in text and "passport" in text:
                header_index = idx
                break

        # fallback —á–µ—Ä–µ–∑ "Appointment Details"
        if header_index is None:
            for idx, line in enumerate(lines):
                text = " ".join(w["text"] for w in line).lower()
                if "appointment" in text and "details" in text:
                    if idx + 1 < len(lines):
                        header_index = idx + 1
                        break

        if header_index is None or header_index >= len(lines):
            return []

        header_line = lines[header_index]
        header_cells = self._build_header_cells(header_line)
        if not header_cells:
            return []

        column_map = self._map_header_cells_to_logical_columns(header_cells)
        if not column_map:
            return []

        # --- –ê–ì–†–ï–ì–ê–¢–û–† –°–¢–†–û–ö –í –û–î–ù–£ –ó–ê–ü–ò–°–¨ –ó–ê–Ø–í–ò–¢–ï–õ–Ø ---
        data_start = header_index + 1
        applicants_raw_rows = []
        current_row = None
        empty_rows_in_a_row = 0

        for line in lines[data_start:]:
            line_text = " ".join(w["text"] for w in line).strip()
            low = line_text.lower()

            if any(
                stop in low
                for stop in [
                    "payment invoice",
                    "declaration",
                    "please note",
                    "¬© vfs global",
                    "thank you",
                    "for more visa information",
                ]
            ):
                break

            row = self._assign_line_to_columns(line, column_map)

            has_any_value = any(
                (row.get(k) or "").strip()
                for k in (
                    "name",
                    "passport",
                    "time",
                    "category",
                    "reference",
                    "special_reference",
                )
            )

            if not has_any_value:
                empty_rows_in_a_row += 1
                if empty_rows_in_a_row >= 2:
                    break
                continue
            else:
                empty_rows_in_a_row = 0

            new_has_name = bool((row.get("name") or "").strip())
            new_has_passport = bool((row.get("passport") or "").strip())

            starts_new_applicant = False
            if current_row is not None and (current_row.get("name") or current_row.get("passport")):
                if new_has_name or new_has_passport:
                    starts_new_applicant = True

            if starts_new_applicant:
                applicants_raw_rows.append(current_row)
                current_row = row
            else:
                if current_row is None:
                    current_row = row
                else:
                    for key in column_map.keys():
                        old_val = (current_row.get(key) or "").strip()
                        new_val = (row.get(key) or "").strip()
                        if new_val:
                            if old_val:
                                current_row[key] = f"{old_val} {new_val}"
                            else:
                                current_row[key] = new_val

        if current_row is not None:
            applicants_raw_rows.append(current_row)

        applicants = []
        for raw_row in applicants_raw_rows:
            applicant = self._build_applicant_object(raw_row)
            applicants.append(applicant)

        return applicants

    # ---------------------- APPLICANT POST-PROCESS ---------------------- #

    @staticmethod
    def _passport_looks_valid(passport: str) -> bool:
        """
        –ü–∞—Å–ø–æ—Ä—Ç:
        - 5‚Äì15 —Å–∏–º–≤–æ–ª–æ–≤
        - —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/*/x/X
        - –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Ü–∏—Ñ—Ä–∞ –∏–ª–∏ –º–∞—Å–∫–∏—Ä—É—é—â–∏–π —Å–∏–º–≤–æ–ª (*, x, X)
        """
        if not passport:
            return False

        p_raw = passport.strip()
        # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–æ–±—â–µ
        p = re.sub(r"\s+", "", p_raw)

        if len(p) < 5 or len(p) > 15:
            return False

        # —Ç–æ–ª—å–∫–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        if not re.fullmatch(r"[A-Za-z0-9*Xx]+", p):
            return False

        # –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ü–∏—Ñ—Ä–∞ –∏–ª–∏ –º–∞—Å–∫–∞
        if not any(ch.isdigit() or ch in "*xX" for ch in p):
            return False

        return True

    @staticmethod
    def _is_valid_applicant(applicant: dict) -> bool:
        """
        –§–∏–ª—å—Ç—Ä—É–µ–º —à—É–º:
        - —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "Your appointment has / Turkey / Bulgaria Visa Application ..."
        - –æ—Å—Ç–∞–≤–ª—è–µ–º:
          - –ª–∏–±–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º –ø–∞—Å–ø–æ—Ä—Ç–æ–º
          - –ª–∏–±–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∏–º—è –ø–æ—Ö–æ–∂–µ –Ω–∞ –§–ò–û (2+ —Å–ª–æ–≤–∞, –±–µ–∑ —Ü–∏—Ñ—Ä)
        """
        name = (applicant.get("name") or "").strip()
        passport = (applicant.get("passport") or "").strip()

        # –ï—Å–ª–∏ –ø–∞—Å–ø–æ—Ä—Ç –≤—ã–≥–ª—è–¥–∏—Ç –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–º ‚Äî —É–∂–µ –æ–∫.
        if VisaAppointmentParser._passport_looks_valid(passport):
            return True

        if not name or len(name) < 3:
            return False
        if any(ch.isdigit() for ch in name):
            return False
        if " " not in name:
            return False

        first_word = name.split()[0].lower()
        stop = {
            "your",
            "arrive",
            "bulgaria",
            "istanbul",
            "turkey",
            "customer/s",
            "please",
        }
        if first_word in stop:
            return False

        return True

    def _filter_invalid_applicants(self, applicants):
        return [a for a in applicants if self._is_valid_applicant(a)]

    def _cut_service_type_suffix(self, text: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç —Ö–≤–æ—Å—Ç—ã –≤–∏–¥–∞ 'Service Type: Premium', 'Service Type - Normal' –∏ —Ç.–ø.
        –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é.
        """
        if not text:
            return text

        # –ò—â–µ–º "Service Type" –∏ –æ–±—Ä–µ–∑–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –Ω–µ–≥–æ
        cleaned = re.split(r"Service\s+Type[:\- ]", text, flags=re.IGNORECASE)[0]

        # –£–¥–∞–ª—è–µ–º —Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã
        return cleaned.strip()

    def _clean_visa_category_text(self, text: str) -> str | None:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:
        - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        - —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã (Customer/s, Reference Number...)
        - –æ—Ç—Ä–µ–∑–∞–µ–º —Ö–≤–æ—Å—Ç 'Service Type: ...'
        - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (Short stay, Application with, Seasonal worker, Short Term)
        - –≤—ã—Ä–µ–∑–∞–µ–º reference-–∫–æ–¥—ã
        - —É–±–∏—Ä–∞–µ–º –æ—Ç–æ—Ä–≤–∞–Ω–Ω—É—é –∫–æ–Ω–µ—á–Ω—É—é —Ü–∏—Ñ—Ä—É (Driver Standard 5 -> Driver Standard)
        """
        if not text:
            return None

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        t = " ".join(str(text).split())
        if len(t) < 3:
            return None

        # —Å–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º —è–≤–Ω—ã–µ –¥–∏—Å–∫–ª–µ–π–º–µ—Ä—ã
        low = t.lower()
        if low.startswith("please be informed") or "corona virus" in low:
            return None

        # —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –ù–ò–ö–û–ì–î–ê –Ω–µ —è–≤–ª—è—é—Ç—Å—è –Ω–∞–∑–≤–∞–Ω–∏–µ–º –≤–∏–∑—ã
        t = re.sub(r"^(Customer/?s|Customer)\s+", "", t, flags=re.IGNORECASE)
        t = re.sub(
            r"^(Reference Number Number|Reference Number)\s+",
            "",
            t,
            flags=re.IGNORECASE,
        )
        t = re.sub(r"^Number\s+", "", t, flags=re.IGNORECASE)

        t = t.strip()

        # üîπ –í–ê–ñ–ù–û: –æ–±—Ä–µ–∑–∞–µ–º —Ö–≤–æ—Å—Ç 'Service Type: ...'
        t = self._cut_service_type_suffix(t)
        if not t:
            return None

        low = t.lower()

        if len(t) < 3:
            return None

        # ===== –≤–∞–∂–Ω—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å =====

        # "3 - Short stay others", "2 - Short stay tourism" –∏ —Ç.–ø.
        m = re.search(r"\d+\s*-\s*short\s+stay[^\n]*", t, re.IGNORECASE)
        if m:
            return m.group(0).strip()

        # "Application with Biometric ( Individual - Bireysel)" –∏ –ø–æ–¥–æ–±–Ω—ã–µ
        if "application with" in low:
            idx = low.index("application with")
            return t[idx:].strip()

        # "Seasonal worker"
        if "seasonal worker" in low:
            return "Seasonal worker"

        # "Short Term Standard", "Short Term"
        if "short term" in low:
            if "standard" in low:
                return "Short Term Standard"
            return "Short Term"

        # ===== –æ–±—â–∏–π sanitizing =====

        # —É–±–∏—Ä–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ reference-–ø–æ–¥–æ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        tokens = []
        for tok in t.split():
            if re.fullmatch(r"[A-Z0-9/]{8,}", tok):
                continue
            tokens.append(tok)
        t = " ".join(tokens).strip()

        parts = t.split()
        if (
            len(parts) >= 2
            and re.fullmatch(r"\d+", parts[-1])
            and any(ch.isalpha() for ch in t)
        ):
            parts = parts[:-1]
            t = " ".join(parts).strip()

        if len(t) > 120:
            return None
        if len(t) < 3:
            return None

        return t or None

    def _refine_visa_category_with_applicants(self, applicants):
        if not applicants:
            return

        cleaned_cats = []

        # 1. –ß–∏—Å—Ç–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —É –∫–∞–∂–¥–æ–≥–æ –∑–∞—è–≤–∏—Ç–µ–ª—è
        for a in applicants:
            raw_cat = a.get("visa_category")
            cleaned = self._clean_visa_category_text(raw_cat)
            if cleaned is not None:
                a["visa_category"] = cleaned
                cleaned_cats.append(cleaned)
            else:
                a["visa_category"] = None

        # 2. –ß–∏—Å—Ç–∏–º –≥–ª–æ–±–∞–ª—å–Ω—É—é, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å ‚Äî –Ω–æ –Ω–µ –¥–∞—ë–º –µ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if self.meta.get("visa_category_global"):
            current = self._clean_visa_category_text(self.meta["visa_category_global"])
            self.meta["visa_category_global"] = current

        # 3. –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–Ω–∞ –≤–º–µ–Ω—è–µ–º–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —É –∑–∞—è–≤–∏—Ç–µ–ª–µ–π ‚Äî
        #    –±–µ—Ä—ë–º —Å–∞–º—É—é –∫–æ—Ä–æ—Ç–∫—É—é –∫–∞–∫ "–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é" –≥–ª–æ–±–∞–ª—å–Ω—É—é
        if cleaned_cats:
            best = sorted(set(cleaned_cats), key=len)[0]
            self.meta["visa_category_global"] = best

        # 4. –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é —Ç—É–¥–∞, –≥–¥–µ —É –∑–∞—è–≤–∏—Ç–µ–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø—É—Å—Ç–∞—è
        if self.meta.get("visa_category_global"):
            for a in applicants:
                if not a.get("visa_category"):
                    a["visa_category"] = self.meta["visa_category_global"]

    # ---------------------- LINE / COLUMN UTILITIES ---------------------- #

    @staticmethod
    def _group_words_into_lines(words, line_tol=3.0):
        words_sorted = sorted(words, key=lambda w: (w["top"], w["x0"]))
        lines = []
        current_line = []
        current_top = None

        for w in words_sorted:
            top = w["top"]
            if not current_line:
                current_line = [w]
                current_top = top
                continue

            if abs(top - current_top) <= line_tol:
                current_line.append(w)
            else:
                lines.append(current_line)
                current_line = [w]
                current_top = top

        if current_line:
            lines.append(current_line)

        return lines

    @staticmethod
    def _build_header_cells(header_line, gap_threshold=20.0):
        header_line_sorted = sorted(header_line, key=lambda w: w["x0"])

        cells = []
        current_cell_words = []
        current_x0 = None
        current_x1 = None

        for w in header_line_sorted:
            if not current_cell_words:
                current_cell_words = [w]
                current_x0 = w["x0"]
                current_x1 = w["x1"]
                continue

            gap = w["x0"] - current_x1
            if gap <= gap_threshold:
                current_cell_words.append(w)
                current_x1 = w["x1"]
            else:
                text = " ".join(ww["text"] for ww in current_cell_words)
                center = (current_x0 + current_x1) / 2.0
                cells.append(
                    {
                        "text": text,
                        "x0": current_x0,
                        "x1": current_x1,
                        "x_center": center,
                    }
                )
                current_cell_words = [w]
                current_x0 = w["x0"]
                current_x1 = w["x1"]

        if current_cell_words:
            text = " ".join(ww["text"] for ww in current_cell_words)
            center = (current_x0 + current_x1) / 2.0
            cells.append(
                {
                    "text": text,
                    "x0": current_x0,
                    "x1": current_x1,
                    "x_center": center,
                }
            )

        return cells

    @staticmethod
    def _map_header_cells_to_logical_columns(header_cells):
        col_map = {}

        for cell in header_cells:
            text = cell["text"].strip()
            low = text.lower()
            x_center = cell["x_center"]

            if "applicant" in low:
                col_map["name"] = x_center
            if "passport" in low:
                col_map["passport"] = x_center
            if "special" in low and "reference" in low:
                col_map["special_reference"] = x_center
            elif "reference" in low:
                col_map["reference"] = x_center
            if "appointment" in low and ("time" in low or "date" in low):
                col_map["time"] = x_center
            if "category" in low:
                col_map["category"] = x_center

        return col_map

    @staticmethod
    def _assign_line_to_columns(line_words, column_map):
        if not column_map:
            return {}

        col_words = {name: [] for name in column_map.keys()}

        for w in sorted(line_words, key=lambda w: w["x0"]):
            word_center = (w["x0"] + w["x1"]) / 2.0

            best_col = None
            best_dist = None
            for col_name, col_center in column_map.items():
                dist = abs(word_center - col_center)
                if best_dist is None or dist < best_dist:
                    best_dist = dist
                    best_col = col_name

            if best_col is not None:
                col_words[best_col].append(w["text"])

        result = {}
        for col_name, words in col_words.items():
            result[col_name] = " ".join(words) if words else ""
        return result

    # ---------------------- BUILD APPLICANT OBJECT ---------------------- #

    def _build_applicant_object(self, row):
        name = (row.get("name") or "").strip() or None
        passport = (row.get("passport") or "").strip() or None
        time_raw = (row.get("time") or "").strip()
        category_row = (row.get("category") or "").strip() or None
        reference = (row.get("reference") or "").strip() or None
        special_ref = (row.get("special_reference") or "").strip() or None

        passport_masked = bool(
            passport and any(ch in passport for ch in ["*", "x", "X"])
        )

        appointment_date = self.meta.get("appointment_date")
        appointment_time = self.meta.get("appointment_time")
        datetime_raw = time_raw if time_raw else None

        if time_raw:
            # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –¥–∞—Ç—É/–≤—Ä–µ–º—è –∏–∑ –≥—Ä—è–∑–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            m_date = re.search(
                r"(\d{4}-\d{2}-\d{2}|\d{2}-\d{2}-\d{4}|\d{2}[./-]\d{2}[./-]\d{4})",
                time_raw,
            )
            if m_date:
                appointment_date = m_date.group(1)

            m_time = re.search(
                r"(\d{1,2}:\d{2}"
                r"(?:\s*(?:am|pm|AM|PM))?"
                r"(?:\s*-\s*\d{1,2}:\d{2}(?:\s*(?:am|pm|AM|PM))?)?)",
                time_raw,
            )
            if m_time:
                appointment_time = m_time.group(1)

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ä–µ–º—è (–æ–±—Ä–µ–∂–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª)
        if appointment_time:
            appointment_time = self._normalize_time(appointment_time)

        # –ï—Å–ª–∏ –∏ –¥–∞—Ç–∞, –∏ –≤—Ä–µ–º—è –∏–∑–≤–µ—Å—Ç–Ω—ã ‚Äì –¥–µ–ª–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π datetime_raw
        if appointment_date and appointment_time:
            datetime_raw = f"{appointment_date} {appointment_time}"

        visa_category = category_row or self.meta.get("visa_category_global")

        applicant = {
            "name": name,
            "passport": passport,
            "passport_masked": passport_masked,
            "appointment_date": appointment_date,
            "appointment_time": appointment_time,
            "datetime_raw": datetime_raw,
            "visa_category": visa_category,
            "reference_number": reference,
            "special_reference_number": special_ref,
        }
        return applicant


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python parse_visa_pdf.py <path_to_pdf>")
        sys.exit(1)

    pdf_path = Path(sys.argv[1])

    if not pdf_path.exists() or pdf_path.suffix.lower() != ".pdf":
        print(f"[–û–®–ò–ë–ö–ê] PDF-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ: {pdf_path}")
        sys.exit(1)

    parser = VisaAppointmentParser(pdf_path)
    result = parser.parse()

    print(json.dumps(result, ensure_ascii=False, indent=2))